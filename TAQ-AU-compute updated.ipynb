{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T20:00:05.472316Z",
     "start_time": "2023-05-28T20:00:04.533826Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date\n",
    "import datetime as dt\n",
    "from datetime import timedelta\n",
    "%matplotlib inline\n",
    "#cross_listed = ['A2M','AFP','AIA','AIZ','BGP','CBL','CNU','CEN','EBO','EVO','FBU','FPH','FSF','GNE','GTK','IFT','IKE','KMD','MEZ','MEQ','MPP','MCY','NTL','NZK','NZM','OCA','OHE','PPH','RBD','SKC','SMP','SM1','SNZ','SKO','SKT','SPK','TGH','TME','TLT','TRA','TWR','VGL','ZEL']\n",
    "o_time = 10*3600*1000000 + 15*60*1000000\n",
    "c_time = 16*3600*1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T20:00:05.642884Z",
     "start_time": "2023-05-28T20:00:05.474312Z"
    }
   },
   "outputs": [],
   "source": [
    "ric_dict = {'ABA': 'ABA',\n",
    "             'AFT': 'KSC',\n",
    "             'AIA': 'CCL',\n",
    "             'AIR': 'NHC',\n",
    "             'ALF': 'TZN',\n",
    "             'AOR': 'SXE',\n",
    "             'APL': 'NZM',\n",
    "             'ARG': 'OMH',\n",
    "             'ARV': 'AAC',\n",
    "             'ATM': 'CGF',\n",
    "             'AUG': 'CRD',\n",
    "             'AWF': 'SOM',\n",
    "             'BGP': 'MOE',\n",
    "             'BLT': 'TTM',\n",
    "             'CAV': 'RKN',\n",
    "             'CDI': 'FRI',\n",
    "             'CEN': 'ABC',\n",
    "             'CMO': 'AKP',\n",
    "             'CNU': 'CNU',\n",
    "             'CVT': 'PAC',\n",
    "             'DGL': 'ZEL',\n",
    "             'EBO': 'EVT',\n",
    "             'ERD': 'LYL',\n",
    "             'EVO': 'MDC',\n",
    "             'FBU': 'FBU',\n",
    "             'FIN': 'FBU',\n",
    "             'FMS': 'RVA',\n",
    "             'FPH': 'SEK',\n",
    "             'FRE': 'FNP',\n",
    "             'FSF': 'HLO',\n",
    "             'GEO': 'HAS',\n",
    "             'GMT': 'VVR',\n",
    "             'GNE': 'SKC',\n",
    "             'GTK': 'LIC',\n",
    "             'GXH': 'GNG',\n",
    "             'HBL': 'ASB',\n",
    "             'HLG': 'MNF',\n",
    "             'IFT': 'OGC',\n",
    "             'IKE': 'HRR',\n",
    "             'IPL': 'EPW',\n",
    "             'KMD': 'INA',\n",
    "             'KPG': 'SXL',\n",
    "             'MAD': 'ASG',\n",
    "             'MCK': 'EOS',\n",
    "             'MCY': 'SPK',\n",
    "             'MEL': 'BWP',\n",
    "             'MET': 'PNI',\n",
    "             'MFT': 'BKL',\n",
    "             'MGL': 'ESV',\n",
    "             'MMH': 'WLL',\n",
    "             'MOA': 'GSW',\n",
    "             'MPG': 'DNK',\n",
    "             'MVN': 'OMN',\n",
    "             'NTL': 'EDE',\n",
    "             'NWF': 'AXP',\n",
    "             'NZK': 'AOF',\n",
    "             'NZM': 'ISU',\n",
    "             'NZO': 'TPE',\n",
    "             'NZR': 'FET',\n",
    "             'NZX': 'BFG',\n",
    "             'OCA': 'RSG',\n",
    "             'OHE': 'GDF',\n",
    "             'PCT': 'GDI',\n",
    "             'PEB': 'ERA',\n",
    "             'PFI': 'SKT',\n",
    "             'PGC': 'ISD',\n",
    "             'PGW': 'ATS',\n",
    "             'PIL': 'FMS',\n",
    "             'PLX': 'BSA',\n",
    "             'POT': 'NWL',\n",
    "             'PPH': 'NGI',\n",
    "             'RAK': 'CDV',\n",
    "             'RBC': 'AJL',\n",
    "             'RBD': 'LOV',\n",
    "             'RYM': 'WTC',\n",
    "             'SAN': 'CWP',\n",
    "             'SCL': 'LEP',\n",
    "             'SCT': 'PCG',\n",
    "             'SCY': 'FSA',\n",
    "             'SEA': 'ALK',\n",
    "             'SEK': 'ONT',\n",
    "             'SKC': 'GOZ',\n",
    "             'SKL': 'IDR',\n",
    "             'SKO': 'CRR',\n",
    "             'SKT': 'NWH',\n",
    "             'SLI': 'FLN',\n",
    "             'SML': 'IRE',\n",
    "             'SPG': 'SLC',\n",
    "             'SPK': 'BLD',\n",
    "             'SPN': 'PHI',\n",
    "             'SPY': 'PMP',\n",
    "             'STU': 'FLK',\n",
    "             'SUM': 'SIQ',\n",
    "             'TGG': 'OCL',\n",
    "             'TGH': 'DFM',\n",
    "             'THL': 'CKF',\n",
    "             'TLL': 'CII',\n",
    "             'TLT': 'URF',\n",
    "             'TME': 'TME',\n",
    "             'TPW': 'APE',\n",
    "             'TRA': 'MVP',\n",
    "             'TRS': 'TGP',\n",
    "             'TTK': 'EZL',\n",
    "             'TWR': 'DCG',\n",
    "             'VCT': 'PTM',\n",
    "             'VGL': 'HSN',\n",
    "             'VHP': 'RFF',\n",
    "             'VIL': 'XAM',\n",
    "             'WDT': 'HOM',\n",
    "             'WHS': 'WBA',\n",
    "             'ZEL': 'DLX'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T20:00:05.781489Z",
     "start_time": "2023-05-28T20:00:05.645853Z"
    }
   },
   "outputs": [],
   "source": [
    "ric_dict2 =  {'ABA': 'CDP',\n",
    "             'AFT': 'CVC',\n",
    "             'AIA': 'DOW',\n",
    "             'AIR': 'GWA',\n",
    "             'ALF': 'BUL',\n",
    "             'AOR': 'ARF',\n",
    "             'APL': 'AVJ',\n",
    "             'ARG': 'Z1P',\n",
    "             'ARV': 'AGI',\n",
    "             'ATM': 'SGM',\n",
    "             'AUG': 'QIP',\n",
    "             'AWF': 'SGH',\n",
    "             'BGP': 'GOW',\n",
    "             'BLT': 'HTA',\n",
    "             'CAV': 'MHJ',\n",
    "             'CDI': 'AJD',\n",
    "             'CEN': 'TNE',\n",
    "             'CMO': 'CEN',\n",
    "             'CNU': 'BVS',\n",
    "             'CVT': 'MYS',\n",
    "             'DGL': 'TBR',\n",
    "             'EBO': 'EQT',\n",
    "             'ERD': 'FID',\n",
    "             'EVO': 'LVH',\n",
    "             'FBU': 'CHC',\n",
    "             'FIN': 'CHC',\n",
    "             'FMS': 'MRN',\n",
    "             'FPH': 'CAR',\n",
    "             'FRE': 'CGL',\n",
    "             'FSF': 'TGR',\n",
    "             'GEO': 'AGG',\n",
    "             'GMT': 'SPL',\n",
    "             'GNE': 'GTY',\n",
    "             'GTK': 'AIA',\n",
    "             'GXH': 'REX',\n",
    "             'HBL': 'EML',\n",
    "             'HLG': 'SLK',\n",
    "             'IFT': 'HT1',\n",
    "             'IKE': 'UOS',\n",
    "             'IPL': 'VLW',\n",
    "             'KMD': 'RHL',\n",
    "             'KPG': 'JHC',\n",
    "             'MAD': 'CZZ',\n",
    "             'MCK': 'ENN',\n",
    "             'MCY': 'DHG',\n",
    "             'MEL': 'NAN',\n",
    "             'MET': 'JIN',\n",
    "             'MFT': 'HUB',\n",
    "             'MGL': 'VAH',\n",
    "             'MMH': 'RND',\n",
    "             'MOA': 'PSI',\n",
    "             'MPG': 'BKY',\n",
    "             'MVN': 'VTG',\n",
    "             'NTL': 'YOJ',\n",
    "             'NWF': 'RUL',\n",
    "             'NZK': 'MTO',\n",
    "             'NZM': 'IFN',\n",
    "             'NZO': 'CIA',\n",
    "             'NZR': 'ADH',\n",
    "             'NZX': 'ERF',\n",
    "             'OCA': 'CMW',\n",
    "             'OHE': '3PL',\n",
    "             'PCT': 'WGX',\n",
    "             'PEB': 'FLC',\n",
    "             'PFI': 'CL1',\n",
    "             'PGC': 'CCV',\n",
    "             'PGW': 'BNO',\n",
    "             'PIL': 'YAL',\n",
    "             'PLX': 'DNA',\n",
    "             'POT': 'WGN',\n",
    "             'PPH': 'CMA',\n",
    "             'RAK': 'NMT',\n",
    "             'RBC': 'DWS',\n",
    "             'RBD': 'KGN',\n",
    "             'RYM': 'WEB',\n",
    "             'SAN': 'SRV',\n",
    "             'SCL': 'NBL',\n",
    "             'SCT': 'IDX',\n",
    "             'SCY': 'WAF',\n",
    "             'SEA': 'FBR',\n",
    "             'SEK': 'MAQ',\n",
    "             'SKC': 'SCO',\n",
    "             'SKL': 'ARQ',\n",
    "             'SKO': 'DDR',\n",
    "             'SKT': 'GEM',\n",
    "             'SLI': 'PSQ',\n",
    "             'SML': 'IVC',\n",
    "             'SPG': 'BLA',\n",
    "             'SPK': 'CSR',\n",
    "             'SPN': 'ZIM',\n",
    "             'SPY': 'PEA',\n",
    "             'STU': 'MVF',\n",
    "             'SUM': 'REH',\n",
    "             'TGG': 'HPI',\n",
    "             'TGH': 'PPC',\n",
    "             'THL': 'MP1',\n",
    "             'TLL': 'BLX',\n",
    "             'TLT': 'NVL',\n",
    "             'TME': 'OML',\n",
    "             'TPW': 'PPH',\n",
    "             'TRA': 'SIV',\n",
    "             'TRS': 'ARB',\n",
    "             'TTK': 'NEW',\n",
    "             'TWR': 'CDD',\n",
    "             'VCT': 'AHG',\n",
    "             'VGL': 'CLW',\n",
    "             'VHP': 'FXL',\n",
    "             'VIL': 'BRL',\n",
    "             'WDT': 'FDM',\n",
    "             'WHS': 'CNI',\n",
    "             'ZEL': 'BGA'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T20:00:05.796448Z",
     "start_time": "2023-05-28T20:00:05.785478Z"
    }
   },
   "outputs": [],
   "source": [
    "cross_ric_dict = {'AFT.NZ':'AFP.AX', 'AIA.NZ':'AIA.AX','AIR.NZ':'AIZ.AX','ATM.NZ':'A2M.AX','BGP.NZ':'BGP.AX','CBL.NZ':'CBL.AX','CEN.NZ':'CEN.AX','CNU.NZ':'CNU.AX','EBO.NZ':'EBO.AX','EVO.NZ':'EVO.AX','FBU.NZ':'FBU.AX','FPH.NZ':'FPH.AX','FSF.NZ':'FSF.AX','GNE.NZ':'GNE.AX','GTK.NZ':'GTK.AX','IFT.NZ':'IFT.AX','IKE.NZ':'IKE.AX','KMD.NZ':'KMD.AX','MCY.NZ':'MCY.AX','MEL.NZ':'MEZ.AX','MET.NZ':'MEQ.AX','MPG.NZ':'MPP.AX','NTL.NZ':'NTL.AX','NZK.NZ':'NZK.AX','NZM.NZ':'NZM.AX','OCA.NZ':'OCA.AX','OHE.NZ':'OHE.AX','PPH.NZ':'PPH.AX','RBD.NZ':'RBD.AX','SKC.NZ':'SKC.AX','SKO.NZ':'SKO.AX','SKT.NZ':'SKT.AX','SML.NZ':'SM1.AX','SPK.NZ':'SPK.AX','SPY.NZ':'SMP.AX','SUM.NZ':'SNZ.AX','TGH.NZ':'TGH.AX','TLT.NZ':'TLT.AX','TME.NZ':'TME.AX','TRA.NZ':'TRA.AX','TWR.NZ':'TWR.AX','TGL.NZ':'TGL.AX','ZEL.NZ':'ZEL.AX'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T20:00:05.812405Z",
     "start_time": "2023-05-28T20:00:05.800437Z"
    }
   },
   "outputs": [],
   "source": [
    "au_cross = [element.split('.')[0] for element in cross_ric_dict.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T20:00:05.828363Z",
     "start_time": "2023-05-28T20:00:05.816395Z"
    }
   },
   "outputs": [],
   "source": [
    "time_df = pd.DataFrame([o_time,c_time], columns=['adj mtime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T20:00:10.336328Z",
     "start_time": "2023-05-28T20:00:05.833351Z"
    }
   },
   "outputs": [],
   "source": [
    "def metric(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    df['venue'] = df['#RIC'].str.split('.', expand=True)[1]\n",
    "    df['stock'] = df['#RIC'].str.split('.', expand=True)[0]\n",
    "    # df['timestamp'] = (df['Date[L]'] + df['Time[L]'])\n",
    "\n",
    "    #correct daylight saving \n",
    "    df['timestamp'] = pd.to_datetime(df['Date-Time'], utc = True)\n",
    "    df['timestamp'] = df['timestamp'].dt.tz_convert('Australia/Sydney')\n",
    "    df['date'] = df['timestamp'].dt.date\n",
    "\n",
    "    df['Price'] = df.groupby(['stock','date'])['Price'].shift(-2)\n",
    "    df['Volume'] = df.groupby(['stock','date'])['Volume'].shift(-2)\n",
    "    df['Buyer ID'] = df.groupby(['stock','date'])['Buyer ID'].shift(-2)\n",
    "    df['Seller ID'] = df.groupby(['stock','date'])['Seller ID'].shift(-2)\n",
    "    df['Qualifiers'] = df.groupby(['stock','date'])['Qualifiers'].shift(-2)\n",
    "    df['Tick Dir.'] = df.groupby(['stock','date'])['Tick Dir.'].shift(-2)\n",
    "    df = df[(df['Price'].notnull())|(df['Bid Price'].notnull())]\n",
    "   \n",
    "    #continue other metric\n",
    "\n",
    "    df['value'] = df['Price']*df['Volume']\n",
    "    #\n",
    "    df['fee'] = df['value'].apply(lambda x: min(0.000015*x, 75))\n",
    "\n",
    "    df['trades'] = np.where(df['Price'].notnull(),1,0)\n",
    "\n",
    "    df['time'] = df['timestamp'].dt.time\n",
    "    #time in microsecond \n",
    "    df['mtime'] = df['time'].apply(lambda x: x.hour * 3600*1000000 + x.minute * 60 *1000000 + x.second *1000000+ x.microsecond)\n",
    "    df['adj mtime'] = np.where(((df['date']>date(2017,10,1))&(df['date']<=date(2018,3,31)))|(df['date']>date(2018,10,17)), df['mtime']+3600*1000000,df['mtime'])\n",
    "    df['seq'] = df.index\n",
    "    df = df.merge(time_df, on = ['adj mtime'], how = 'outer')\n",
    "    df = df.sort_values(['adj mtime','seq'])\n",
    "    df[['stock','venue','date']] = df[['stock','venue','date']].ffill()\n",
    "    df['mtime_1m'] = df['adj mtime'] + 60 *1000000\n",
    "\n",
    "    df['Ask Size abs'] =df['Ask Size'] \n",
    "    df['Bid Size abs'] = df['Bid Size'] \n",
    "    # fil in quoting status of the previous quote\n",
    "    quotes_cols = ['Bid Price', 'Bid Size', 'Ask Price', 'Ask Size', 'Ask Size abs', 'Bid Size abs']\n",
    "    # df = df.sort_values(['venue', 'extra_timestamp'])\n",
    "    df[quotes_cols] = df.groupby(['venue'])[quotes_cols].fillna(method='ffill')\n",
    "\n",
    "    df['MidQuote'] = np.where((df['Bid Price'] != 0) & (df['Ask Price'] != 0),\n",
    "                                      (df['Bid Price'] + df['Ask Price']) / 2.0, np.nan)\n",
    "\n",
    "    # assign trade direction\n",
    "\n",
    "    df['direction'] = np.where(df['Price']>df['MidQuote'], 'B',np.nan)\n",
    "    df['direction'] = np.where(df['Price']<df['MidQuote'],'S',df['direction'])\n",
    "    df['direction'] = np.where(df['Price']==df['MidQuote'],'C',df['direction'])\n",
    "\n",
    "    # o_time = dt.time(10, 0, 0)\n",
    "    # c_time = dt.time(17, 0, 0)\n",
    "\n",
    "    \n",
    "    df = df[(df['adj mtime'] >= o_time) & (df['adj mtime'] <= c_time)]\n",
    "#     df.to_csv('C:/Users/anche/NZ/trth data/au_tester/'+'2_'+filename.split('/')[-1])\n",
    "    daily_value = df.groupby(['date','stock'])['value'].sum().reset_index()\n",
    "    daily_value = daily_value.rename(columns = {'value':'daily_value'})\n",
    "    df = df.merge(daily_value, on = ['date','stock'], how = 'left')\n",
    "    df['value'] = df['Price']*df['Volume']\n",
    "    df['issue'] = np.where(((df['direction'] == 'S') & (df['Price'] < df['Bid Price'])) | (\n",
    "            (df['direction'] == 'B') & (df['Price'] > df['Ask Price'])), 1, 0)\n",
    "\n",
    "    df['vol_issue'] = np.where(((df['direction'] == 'S') & (df['Volume'] > df['Bid Size abs'])) | (\n",
    "            (df['direction'] == 'B') & (df['Volume'] > df['Ask Size abs'])), 1, 0)\n",
    "    \n",
    "    df['quote_alive'] = df.groupby(['stock','date'])['adj mtime'].shift(-1) -  df['adj mtime']\n",
    "#     df['quote_alive'] = df['quote_alive'].replace(0, np.nan)\n",
    "#     df['quote_alive'] = df['quote_alive'].fillna(method='ffill')\n",
    "    \n",
    "    df['value win'] = np.where(df['value']>df['value'].quantile(0.95),df['value'].quantile(0.95),df['value'])\n",
    "#     df_cross = df[df['stock'].isin(cross_listed)]\n",
    "#     df_cross['value win'] = np.where(df_cross['value']>df_cross['value'].quantile(0.95),df_cross['value'].quantile(0.95),df_cross['value'])\n",
    "    \n",
    "    df['Quoted Spread'] = np.where(\n",
    "        (df['Ask Price'] != 0) & (df['Bid Price'] != 0) & (df['Ask Price'] > df['Bid Price']),\n",
    "        df['Ask Price'] - df['Bid Price'], np.nan)\n",
    "    df['Quoted Spread bps'] = np.where(\n",
    "                    (df['Ask Price'] != 0) & (df['Bid Price'] != 0) & (df['Ask Price'] > df['Bid Price']),\n",
    "                    (df['Ask Price'] - df['Bid Price'])/(df['MidQuote']), np.nan)\n",
    "\n",
    "    df['Quoted Spread_TW'] = df['Quoted Spread'] * df['quote_alive']\n",
    "    df['Quoted Spread bps_TW'] = df['Quoted Spread bps'] * df['quote_alive']\n",
    "    \n",
    "    df[f'at tick'] = np.where(\n",
    "                ((df['Quoted Spread'] < 0.01) & (df['MidQuote'] > 0.2)) | (\n",
    "                    (df['Quoted Spread'] < 0.001) & (df['MidQuote'] < 0.2)), 1, 0)\n",
    "    df[f'at tick time'] = df['at tick'] * df['quote_alive']\n",
    "    b_sel = df.direction == 'B'\n",
    "    df.loc[b_sel, f'Effective Spread'] = 2 * (df.loc[b_sel, f'Price'] -df.loc[b_sel, 'MidQuote'])\n",
    "    s_sel = df.direction == 'S'\n",
    "    df.loc[s_sel, f'Effective Spread'] = 2 * (df.loc[s_sel, 'MidQuote'] -df.loc[s_sel, f'Price'])\n",
    "\n",
    "    df[f'Effective Spread_VW'] = df[f'Effective Spread'] * df[f'value']\n",
    "    df.loc[b_sel, f'Effective Spread bps'] = 2 * (df.loc[b_sel, f'Price'] -df.loc[b_sel, 'MidQuote'])/df.loc[b_sel, 'MidQuote']\n",
    "    df.loc[s_sel, f'Effective Spread bps'] = 2 * (df.loc[s_sel, 'MidQuote'] -df.loc[s_sel, f'Price'])/df.loc[s_sel, 'MidQuote']\n",
    "\n",
    "    df[f'Effective Spread bps_VW'] = df[f'Effective Spread bps'] * df[f'value']\n",
    "    df['Depth'] = df['Bid Size abs'] + df['Ask Size abs']\n",
    "    df['Depth_TW'] = df['Depth'] * df['quote_alive']\n",
    "\n",
    "    df['Depth_dollar'] = df['Bid Size abs']*df['Bid Price'] + df['Ask Size abs']*df['Ask Price']\n",
    "    df['Depth_dollar_TW'] = df['Depth_dollar'] * df['quote_alive']\n",
    "    \n",
    "    trade_size = df.groupby(['date','stock'])['value'].mean().reset_index()\n",
    "    trade_size = trade_size.rename(columns = {'value':'trade size'})\n",
    "    \n",
    "    Depth_TW = (df.groupby(['stock', 'date'])['Depth_TW'].sum() / \\\n",
    "                                        df[df['Depth_TW'].notnull()].groupby(['stock', 'date'])['quote_alive'].sum()).reset_index()\n",
    "    Depth_TW = Depth_TW.rename(columns = {0:'Depth'})\n",
    "\n",
    "    Depth_dollar_TW = (df.groupby(['stock', 'date'])['Depth_dollar_TW'].sum() / \\\n",
    "                                df[df['Depth_dollar_TW'].notnull()].groupby(['stock', 'date'])['quote_alive'].sum()).reset_index()\n",
    "    Depth_dollar_TW = Depth_dollar_TW.rename(columns = {0:'Depth_dollar'})\n",
    "    \n",
    "    df_trades = df[df['Price'].notnull()]\n",
    "    Quoted_spread_TW = (df.groupby(['stock', 'date'])['Quoted Spread_TW'].sum() / \\\n",
    "                                df[df['Quoted Spread_TW'].notnull()].groupby(['stock', 'date'])['quote_alive'].sum()).reset_index()\n",
    "    Quoted_spread_TW = Quoted_spread_TW.rename(columns = {0:'quoted spread'})\n",
    "    Quoted_spread_bps_TW = (df.groupby(['stock', 'date'])['Quoted Spread bps_TW'].sum() / \\\n",
    "                                        df[df['Quoted Spread_TW'].notnull()].groupby(['stock', 'date'])['quote_alive'].sum()).reset_index()\n",
    "    Quoted_spread_bps_TW = Quoted_spread_bps_TW.rename(columns = {0:'quoted spread bps'})\n",
    "\n",
    "    df['MidQuote_TW'] = df['MidQuote'] * df['quote_alive']\n",
    "\n",
    "    midpoint_TW = (df.groupby(['stock', 'date'])['MidQuote_TW'].sum() / \\\n",
    "                                df[df['MidQuote_TW'].notnull()].groupby(['stock', 'date'])['quote_alive'].sum()).reset_index()\n",
    "    midpoint_TW = midpoint_TW.rename(columns = {0:'midpoint'})\n",
    "    \n",
    "    min_tick_TW = (df.groupby(['stock', 'date'])['at tick time'].sum() / \\\n",
    "                      df.groupby(['stock', 'date'])[\n",
    "                          'quote_alive'].sum()).reset_index()\n",
    "    min_tick_TW = min_tick_TW.rename(columns = {0:'tick time'})\n",
    "    \n",
    "    Value_weighted_Effective_Spread = (df.groupby(['stock', 'date'])['Effective Spread_VW'].sum() / \\\n",
    "                                df[df['Effective Spread_VW'].notnull()].groupby(['stock', 'date'])['value'].sum()).reset_index()\n",
    "\n",
    "    Value_weighted_Effective_Spread = Value_weighted_Effective_Spread.rename(columns = {0:'value weighted effective spread'})\n",
    "\n",
    "    Value_weighted_Effective_Spread_bps = ((df.groupby(['stock', 'date'])['Effective Spread bps_VW'].sum() / \\\n",
    "                                df[df['Effective Spread bps_VW'].notnull()].groupby(['stock', 'date'])['value'].sum())*10000).reset_index()\n",
    "    Value_weighted_Effective_Spread_bps = Value_weighted_Effective_Spread_bps.rename(columns = {0:'value weighted effective spread bps'})\n",
    "\n",
    "    #realized spread\n",
    "    df = df.sort_values('adj mtime',ascending = True)\n",
    "    df_realized = pd.merge_asof(df,df[['stock','date','adj mtime','MidQuote']],left_on=['mtime_1m'], right_on=['adj mtime'],\n",
    "                                             by=['stock','date'], suffixes=('', '_1m_matched'),\n",
    "                                             allow_exact_matches=False)\n",
    "\n",
    "\n",
    "    b_sel = df_realized.direction == 'B'\n",
    "    df_realized.loc[b_sel, f'Realized Spread'] = 2 * (df_realized.loc[b_sel, f'Price'] -df_realized.loc[b_sel, 'MidQuote_1m_matched'])\n",
    "    s_sel = df_realized.direction == 'S'\n",
    "    df_realized.loc[s_sel, f'Realized Spread'] = 2 * (df_realized.loc[s_sel, 'MidQuote_1m_matched'] -df_realized.loc[s_sel, f'Price'])\n",
    "\n",
    "    df_realized[f'Realized Spread_VW'] = df_realized[f'Realized Spread'] * df_realized[f'value']\n",
    "    df_realized.loc[b_sel, f'Realized Spread bps'] = 2 * (df_realized.loc[b_sel, f'Price'] -df_realized.loc[b_sel, 'MidQuote_1m_matched'])/df_realized.loc[b_sel, 'MidQuote_1m_matched']\n",
    "    df_realized.loc[s_sel, f'Realized Spread bps'] = 2 * (df_realized.loc[s_sel, 'MidQuote_1m_matched'] -df_realized.loc[s_sel, f'Price'])/df_realized.loc[s_sel, 'MidQuote_1m_matched']\n",
    "\n",
    "    df_realized[f'Realized Spread bps_VW'] = df_realized[f'Realized Spread bps'] * df_realized[f'value']\n",
    "    df_spreads = df_realized[df_realized['Price'].notnull()][['stock','date','adj mtime','Qualifiers','value','Price','Volume','direction','Effective Spread','Realized Spread','Effective Spread bps','Realized Spread bps','MidQuote','MidQuote_1m_matched','Quoted Spread','Quoted Spread bps']]\n",
    "           \n",
    "    Value_weighted_Realized_Spread = (df_realized.groupby(['stock', 'date'])['Realized Spread_VW'].sum() / \\\n",
    "                                df_realized[df_realized['Realized Spread_VW'].notnull()].groupby(['stock', 'date'])['value'].sum()).reset_index()\n",
    "\n",
    "    Value_weighted_Realized_Spread = Value_weighted_Realized_Spread.rename(columns = {0:'value weighted realized spread'})\n",
    "\n",
    "    \n",
    "    Value_weighted_Realized_Spread_bps = ((df_realized.groupby(['stock', 'date'])['Realized Spread bps_VW'].sum() / \\\n",
    "                                df_realized[df_realized['Realized Spread bps_VW'].notnull()].groupby(['stock', 'date'])['value'].sum())*10000).reset_index()\n",
    "    Value_weighted_Realized_Spread_bps = Value_weighted_Realized_Spread_bps.rename(columns = {0:'value weighted realized spread bps'})\n",
    "  \n",
    "    '''\n",
    "    #compute market order \n",
    "    market_order = df.groupby(['stock','date','adj mtime'])['value'].sum().reset_index()\n",
    "\n",
    "    daily_market_order = market_order.groupby(['stock','date'])['value'].mean().reset_index()\n",
    "    daily_market_order = daily_market_order.rename(columns = {'value':'market order value'})\n",
    "\n",
    "    #compute price order\n",
    "\n",
    "    df['bid diff'] = df.groupby(['stock','venue','date'])['Bid Price'].diff() \n",
    "    df['bid order'] = np.where(df['bid diff']==0,df.groupby(['stock','venue','date'])['Bid Size abs'].diff(),np.nan )\n",
    "    df['bid order'] = np.where(df['bid diff']>0,df['Bid Size abs'],df['bid order'])\n",
    "\n",
    "    df['bid order'] = np.where(df['bid order']>0,df['bid order'],np.nan)\n",
    "    \n",
    "    df['ask diff'] = df.groupby(['stock','venue','date'])['Ask Price'].diff() \n",
    "    df['ask order'] = np.where(df['ask diff']==0,df.groupby(['stock','venue','date'])['Ask Size abs'].diff(),np.nan )\n",
    "    df['ask order'] = np.where(df['ask diff']<0,df['Ask Size abs'],df['ask order'])\n",
    "    df['ask order'] = np.where(df['ask order']>0,df['ask order'],np.nan)\n",
    "#     df.to_csv('C:/Users/anche/NZ/trth data/au_tester/'+'3_'+filename.split('/')[-1])\n",
    "    daily_bid_order = df.groupby(['stock','date'])['bid order'].mean().reset_index()\n",
    "    daily_bid_order = daily_bid_order.rename(columns = {'bid order':'bid order value'})\n",
    "\n",
    "    daily_ask_order = df.groupby(['stock','date'])['ask order'].mean().reset_index()\n",
    "    daily_ask_order = daily_ask_order.rename(columns = {'ask order':'ask order value'})\n",
    "\n",
    "    daily_order = daily_bid_order.merge(daily_ask_order, on = ['stock','date'])\n",
    "    '''\n",
    "    df_trades_buy = df[df['direction'] == 'B']  \n",
    "    if len(df_trades_buy)>1:\n",
    "        df_trades_buy = df_trades_buy.reset_index()\n",
    "        #if the difference in time between each two trades is more than 200, then start a new trade string \n",
    "        df_trades_buy['trade_dif'] = df_trades_buy['adj mtime'] - df_trades_buy.groupby(['date','stock'])['adj mtime'].shift()\n",
    "\n",
    "        df_trades_buy['trade_string_index'] = int()\n",
    "\n",
    "        df_trades_buy['trade_string_index'] = (df_trades_buy['trade_dif'] > 200000).cumsum()\n",
    "\n",
    "        buy_string_market_order = df_trades_buy.groupby(['date','stock','trade_string_index'])['value'].sum().rename('market_order').reset_index()\n",
    "        buy_string_limit_order = df_trades_buy.groupby(['date','stock','trade_string_index'])['value'].apply(lambda x: x.iloc[-1:].mean()).rename('limit_order').reset_index()\n",
    "\n",
    "        buy_market_order = buy_string_market_order.groupby(['date','stock'])['market_order'].mean().rename('buy_market_order').reset_index()\n",
    "        buy_limit_order = buy_string_limit_order.groupby(['date','stock'])['limit_order'].mean().rename('buy_limit_order').reset_index()\n",
    "\n",
    "        print(buy_limit_order)\n",
    "\n",
    "    df_trades_sell = df[df['direction'] == 'S']  \n",
    "    if len(df_trades_sell)>1:\n",
    "        df_trades_sell = df_trades_sell.reset_index()\n",
    "        df_trades_sell['trade_dif'] = df_trades_sell['adj mtime'] - df_trades_sell.groupby(['date','stock'])['adj mtime'].shift()\n",
    "        # df_trades_buy.to_csv('E:/Sean/OPR/new_data/tester_out/df_trades_buy.csv')\n",
    "        df_trades_sell['trade_string_index'] = int()\n",
    "\n",
    "        df_trades_sell['trade_string_index'] = (df_trades_sell['trade_dif'] > 200000).cumsum()\n",
    "        sell_string_market_order = df_trades_sell.groupby(['date','stock','trade_string_index'])['value'].sum().rename('market_order').reset_index()\n",
    "        sell_string_limit_order = df_trades_sell.groupby(['date','stock','trade_string_index'])['value'].apply(lambda x: x.iloc[-1:].mean()).rename('limit_order').reset_index()\n",
    "\n",
    "        sell_market_order = sell_string_market_order.groupby(['date','stock'])['market_order'].mean().rename('sell_market_order').reset_index()\n",
    "        sell_limit_order = sell_string_limit_order.groupby(['date','stock'])['limit_order'].mean().rename('sell_limit_order').reset_index()\n",
    "\n",
    "    num_quote_update = df.groupby(['stock','date'])['Bid Price'].count().reset_index()\n",
    "    num_quote_update = num_quote_update.rename(columns = {'Bid Price':'num_quote_update'})\n",
    "    \n",
    "    num_trades = df.groupby(['stock','date'])['Price'].count().reset_index()\n",
    "    num_trades = num_trades.rename(columns = {'Price':'num_trades'})\n",
    "    \n",
    "    daily_value['date'] = pd.to_datetime(daily_value['date'])\n",
    "    Quoted_spread_TW['date'] = pd.to_datetime(Quoted_spread_TW['date'])\n",
    "    Quoted_spread_bps_TW['date'] = pd.to_datetime(Quoted_spread_bps_TW['date'])\n",
    "    Depth_TW['date'] = pd.to_datetime(Depth_TW['date'])\n",
    "    Depth_dollar_TW['date'] = pd.to_datetime(Depth_dollar_TW['date'])\n",
    "    min_tick_TW['date'] = pd.to_datetime(min_tick_TW['date'])\n",
    "    Value_weighted_Effective_Spread['date'] = pd.to_datetime(Value_weighted_Effective_Spread['date'])\n",
    "    Value_weighted_Effective_Spread_bps['date'] = pd.to_datetime(Value_weighted_Effective_Spread_bps['date'])\n",
    "    Value_weighted_Realized_Spread['date'] = pd.to_datetime(Value_weighted_Realized_Spread['date'])\n",
    "    Value_weighted_Realized_Spread_bps['date'] = pd.to_datetime(Value_weighted_Realized_Spread_bps['date'])\n",
    "#     daily_market_order['date'] = pd.to_datetime(daily_market_order['date'])\n",
    "#     daily_order['date'] = pd.to_datetime(daily_order['date'])\n",
    "    try:\n",
    "        buy_market_order['date'] = pd.to_datetime(buy_market_order['date'])\n",
    "        buy_limit_order['date'] = pd.to_datetime(buy_limit_order['date'])\n",
    "    except:\n",
    "        print(filename)\n",
    "    try:    \n",
    "        sell_market_order['date'] = pd.to_datetime(sell_market_order['date'])\n",
    "        sell_limit_order['date'] = pd.to_datetime(sell_limit_order['date'])\n",
    "\n",
    "    except:\n",
    "        print(filename)\n",
    "    num_quote_update['date'] = pd.to_datetime(num_quote_update['date'])\n",
    "    num_trades['date'] = pd.to_datetime(num_trades['date'])\n",
    "    midpoint_TW['date'] = pd.to_datetime(midpoint_TW['date'])\n",
    "    \n",
    "    all_metric = daily_value.merge(Quoted_spread_TW,on = ['stock','date'], how = 'outer')\n",
    "    all_metric = all_metric.merge(Quoted_spread_bps_TW, on=['stock', 'date'], how='outer')\n",
    "    all_metric = all_metric.merge(Depth_TW,on = ['stock','date'], how = 'outer')\n",
    "    all_metric = all_metric.merge(Depth_dollar_TW,on = ['stock','date'], how = 'outer')\n",
    "    all_metric = all_metric.merge(min_tick_TW,on = ['stock','date'], how = 'outer')\n",
    "    all_metric = all_metric.merge(Value_weighted_Effective_Spread,on = ['stock','date'], how = 'outer')\n",
    "    all_metric = all_metric.merge(Value_weighted_Effective_Spread_bps,on = ['stock','date'], how = 'outer')\n",
    "    all_metric = all_metric.merge(Value_weighted_Realized_Spread,on = ['stock','date'], how = 'outer')\n",
    "    all_metric = all_metric.merge(Value_weighted_Realized_Spread_bps,on = ['stock','date'], how = 'outer')\n",
    "#     all_metric = all_metric.merge(daily_market_order,on = ['stock','date'], how = 'outer')\n",
    "#     all_metric = all_metric.merge(daily_order,on = ['stock','date'], how = 'outer')\n",
    "    all_metric = all_metric.merge(num_quote_update,on = ['stock','date'], how = 'outer')\n",
    "    all_metric = all_metric.merge(num_trades,on = ['stock','date'], how = 'outer')\n",
    "    all_metric = all_metric.merge(midpoint_TW,on = ['stock','date'], how = 'outer')\n",
    "    try:\n",
    "        all_metric = all_metric.merge(buy_market_order,on = ['stock','date'], how = 'outer')\n",
    "        all_metric = all_metric.merge(buy_limit_order,on = ['stock','date'], how = 'outer')\n",
    "    except:\n",
    "        print(filename)\n",
    "    try:\n",
    "        all_metric = all_metric.merge(sell_market_order,on = ['stock','date'], how = 'outer')\n",
    "        all_metric = all_metric.merge(sell_limit_order,on = ['stock','date'], how = 'outer')\n",
    "    except:\n",
    "        print(filename)\n",
    "    return (all_metric,df_trades,df_spreads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-28T20:00:04.551Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('C:/Users/anche/NZ/trth data/AORD cross')\n",
    "metric_list = []\n",
    "trades_list = []\n",
    "for file in os.listdir('C:/Users/anche/NZ/trth data/AORD cross'):\n",
    "    if file.split('_')[2].split('.')[0] in list(set(list(ric_dict.values())+list(ric_dict2.values())+au_cross)):\n",
    "        print(file.split('_')[2].split('.')[0])\n",
    "        try:\n",
    "            metric_list.append(metric(file)[0])\n",
    "            trades_list.append(metric(file)[1])\n",
    "        except:\n",
    "            continue\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-28T20:00:04.554Z"
    }
   },
   "outputs": [],
   "source": [
    "all_metrics = pd.concat(metric_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-28T20:00:04.555Z"
    }
   },
   "outputs": [],
   "source": [
    "all_metrics.to_csv('C:/Users/anche/NZ/tables v2/AU metric cross v5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-28T20:00:04.557Z"
    }
   },
   "outputs": [],
   "source": [
    "all_trades = pd.concat(trades_list)\n",
    "all_trades.to_csv('C:/Users/anche/NZ/tables v2/AU cross trades v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-28T20:00:04.560Z"
    }
   },
   "outputs": [],
   "source": [
    "au_quantile = pd.DataFrame(all_trades['value'].quantile([0.1,0.15,0.2,0.25,0.5,0.75,0.8,0.9]))\n",
    "au_quantile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
