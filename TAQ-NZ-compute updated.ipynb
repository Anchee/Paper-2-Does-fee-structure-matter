{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T02:58:35.601695Z",
     "start_time": "2019-10-21T02:58:34.889571Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date\n",
    "import datetime as dt\n",
    "from datetime import timedelta\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T02:58:35.607679Z",
     "start_time": "2019-10-21T02:58:35.603661Z"
    }
   },
   "outputs": [],
   "source": [
    "o_time = 10*3600*1000000 \n",
    "c_time = 17*3600*1000000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T02:58:35.627626Z",
     "start_time": "2019-10-21T02:58:35.609646Z"
    }
   },
   "outputs": [],
   "source": [
    "time_df = pd.DataFrame([o_time,c_time], columns=['adj mtime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T02:58:46.037792Z",
     "start_time": "2019-10-21T02:58:36.813426Z"
    }
   },
   "outputs": [],
   "source": [
    "def metric(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "#     print(filename)\n",
    "#     print(len(df))\n",
    "    \n",
    "    if len(df)>0:\n",
    "        df['venue'] = df['#RIC'].str.split('.', expand=True)[1]\n",
    "        df['stock'] = df['#RIC'].str.split('.', expand=True)[0]\n",
    "        \n",
    "        # df['timestamp'] = (df['Date[L]'] + df['Time[L]'])\n",
    "        df['timestamp'] = pd.to_datetime(df['Date-Time'], utc = True)\n",
    "        df['timestamp'] = df['timestamp'].dt.tz_convert('Pacific/Auckland')\n",
    "        df['date'] = df['timestamp'].dt.date\n",
    "        df['time'] = df['timestamp'].dt.time\n",
    "        #df.to_csv('C:/Users/anche/NZ/trth data/tester_out/'+'1_'+file_name)\n",
    "        #df['adj timestamp'] = df['timestamp']-timedelta(hours=13)\n",
    "        # df['adj timestamp'] = df['timestamp']-timedelta(hours=13)\n",
    "        #correct daylight saving \n",
    "        #df['adj timestamp'] = np.where(((df['date']>date(2017,10,1))&(df['date']<=date(2018,3,31)))|(df['date']>date(2018,9,30)), df['adj timestamp']+timedelta(hours=1),df['adj timestamp'])\n",
    "        # df['adj timestamp'] = df['adj timestamp']-timedelta(hours=13)\n",
    "        #correct time \n",
    "        #column went wrong \n",
    "        #df[['Price','Volume','Buyer ID','Seller ID','Qualifiers','Tick Dir.']] = df.groupby(['stock','date'])[['Price','Volume','Buyer ID','Seller ID','Qualifiers','Tick Dir.']].shift(-2)\n",
    "        # df['Price'] = df.groupby(['stock','date'])['Price'].shift(-2)\n",
    "        # df['Volume'] = df.groupby(['stock','date'])['Volume'].shift(-2)\n",
    "        # df['Buyer ID'] = df.groupby(['stock','date'])['Buyer ID'].shift(-2)\n",
    "        # df['Seller ID'] = df.groupby(['stock','date'])['Seller ID'].shift(-2)\n",
    "        # df['Qualifiers'] = df.groupby(['stock','date'])['Qualifiers'].shift(-2)\n",
    "        # df['Tick Dir.'] = df.groupby(['stock','date'])['Tick Dir.'].shift(-2)\n",
    "\n",
    "        # df.to_csv('ARG_v3.csv')\n",
    "        # df = df[df['Type']=='Quote']\n",
    "        #df[['Price','Bid Price','Ask Price','Volume','Bid Size','Ask Size']] = pd.to_numeric(df[['Price','Bid Price','Ask Price','Volume','Bid Size','Ask Size']],errors = 'coerce')\n",
    "        df = df[(df['Price'].notnull())|(df['Bid Price'].notnull())]\n",
    "\n",
    "        #for realized spread (hypothetical timeframe)\n",
    "        # df['TS_1m'] = df['adj timestamp'] + timedelta(minutes=1)\n",
    "\n",
    "        #time in microsecond \n",
    "        df['mtime'] = df['time'].apply(lambda x: x.hour * 3600*1000000 + x.minute * 60 *1000000 + x.second *1000000+ x.microsecond)\n",
    "        df['adj mtime'] = np.where(((df['date']>date(2017,10,1))&(df['date']<=date(2018,3,31)))|(df['date']>date(2018,9,30)), df['mtime']+3600*1000000,df['mtime'])\n",
    "        #df['adj mtime'] = np.where(df['Type']=='Trade',df['adj mtime']-60 *1000000,df['adj mtime'])\n",
    "        df['Ask Size abs'] =df['Ask Size'] \n",
    "        df['Bid Size abs'] = df['Bid Size'] \n",
    "        #df = pd.concat([o_time_df,df.set_index('adj mtime'),c_time_df],axis = 0)\n",
    "        df['seq'] = df.index\n",
    "    #     print(df)\n",
    "        if len(df)>1:\n",
    "            df = df.merge(time_df, on = ['adj mtime'], how = 'outer')\n",
    "            df = df.sort_values(['adj mtime','seq'])\n",
    "            df[['stock','venue','date']] = df[['stock','venue','date']].ffill()\n",
    "            df['mtime_1m'] = df['adj mtime'] + 60 *1000000\n",
    "            df['mtime_1s'] = df['adj mtime'] + 1 *1000000\n",
    "            df['mtime_30s'] = df['adj mtime'] + 30 *1000000\n",
    "            df['mtime_5m'] = df['adj mtime'] + 5 *60 *1000000\n",
    "            # df = pd.merge_asof(df,time_df, on = ['adj mtime'], direction = 'backward')\n",
    "            df['lock'] = np.where(df['Bid Price']==df['Ask Price'],1,0)\n",
    "            # fil in quoting status of the previous quote\n",
    "            quotes_cols = ['Bid Price', 'Bid Size', 'Ask Price', 'Ask Size', 'Ask Size abs', 'Bid Size abs']\n",
    "            # df = df.sort_values(['venue', 'extra_timestamp'])\n",
    "            df[quotes_cols] = df.groupby(['venue','stock','date'])[quotes_cols].fillna(method='ffill')\n",
    "            df['move'] = np.where(df['Bid Price']!=df['Bid Price'].shift(1),'B',np.nan)\n",
    "            df['move'] = np.where(df['Ask Price']!=df['Ask Price'].shift(1),'A',df['move'])\n",
    "\n",
    "            # df['move'] = df['move'].replace({'nan':np.nan})\n",
    "            # df['move'] =df['move'].ffill()\n",
    "            df['quote_direction'] = np.where((df['lock']==1)&(df['move']=='B'),'B',np.nan)\n",
    "            df['quote_direction'] = np.where((df['lock']==1)&(df['move']=='A'),'S',df['quote_direction'])\n",
    "\n",
    "            df['direction'] = df['quote_direction'].replace({'nan':np.nan})\n",
    "            df['direction'] = df.groupby(['venue','stock','date'])['direction'].ffill()\n",
    "            df['direction'] = np.where(df['Price'].notnull(),df['direction'],np.nan)\n",
    "            \n",
    "            df['trad_direction'] = np.where(df['Price']==df['Ask Price'],'B',np.nan)\n",
    "            df['trad_direction'] = np.where(df['Price']==df['Bid Price'],'S',df['trad_direction'])\n",
    "            \n",
    "            df['direction'] = np.where(df['direction'].notnull(),df['direction'],df['trad_direction'])\n",
    "\n",
    "            # df['Bid Price adj'] = np.where((df['lock']==1)&(df['move']=='B'),np.nan,df['Bid Price'])\n",
    "            # df['Ask Price adj'] = np.where((df['lock']==1)&(df['move']=='A'),np.nan,df['Ask Price'])\n",
    "\n",
    "            # df['Bid Price adj'] = np.where((df['lock']==1),np.nan,df['Bid Price'])\n",
    "            # df['Ask Price adj'] = np.where((df['lock']==1),np.nan,df['Ask Price'])\n",
    "\n",
    "            # df['Bid Price adj'] = df['Bid Price adj'].ffill()\n",
    "            # df['Ask Price adj'] = df['Ask Price adj'].ffill()\n",
    "\n",
    "#             df['Bid Price adj'] = np.where((df['lock']==1)&(df['lock'].shift()==0),df['Bid Price'].shift(1),np.nan)\n",
    "#             df['Ask Price adj'] = np.where((df['lock']==1)&(df['lock'].shift()==0),df['Ask Price'].shift(1),np.nan)\n",
    "#             df['Bid Price adj'] = df.groupby(['venue','stock','date'])['Bid Price adj'].ffill()\n",
    "#             df['Ask Price adj'] = df.groupby(['venue','stock','date'])['Ask Price adj'].ffill()\n",
    "#             df['Bid Price adj'] = np.where(df['Bid Price adj'].notnull(), df['Bid Price adj'], df['Bid Price'])\n",
    "#             df['Ask Price adj'] = np.where(df['Ask Price adj'].notnull(), df['Ask Price adj'], df['Ask Price'])\n",
    "            #df.to_csv('C:/Users/anche/NZ/trth data/tester_out/'+'2_'+file_name)\n",
    "            # df['new_index'] = df.groupby(['date','stock','venue','lock'])['Bid Price'].cumcount()\n",
    "            df['Bid Price adj'] = df['Bid Price']\n",
    "            df['Ask Price adj'] = df['Ask Price']\n",
    "\n",
    "\n",
    "            df['MidQuote'] = np.where((df['Bid Price'] != 0) & (df['Ask Price'] != 0),\n",
    "                                              (df['Bid Price'] + df['Ask Price']) / 2.0, np.nan)\n",
    "\n",
    "            df['MidQuote adj'] = np.where((df['Bid Price adj'] != 0) & (df['Ask Price adj'] != 0),\n",
    "                                              (df['Bid Price adj'] + df['Ask Price adj']) / 2.0, np.nan)\n",
    "\n",
    "            # assign trade direction\n",
    "\n",
    "            # df['direction'] = np.where(df['Price']>df['MidQuote'], 'B',np.nan)\n",
    "            # df['direction'] = np.where(df['Price']<df['MidQuote'],'S',df['direction'])\n",
    "            # df['direction'] = np.where(df['Price']==df['MidQuote'],'C',df['direction'])\n",
    "\n",
    "            # o_time = dt.time(10, 0, 0)\n",
    "            # c_time = dt.time(17, 0, 0)\n",
    "            # df = df[(df['time'] > o_time) & (df['time'] < c_time)]\n",
    "\n",
    "            #whether filter by hours trade\n",
    "            #df = df[(df['adj mtime'] >= o_time) & (df['adj mtime'] <= c_time)]\n",
    "            df['NZ Price'] = df['Price']\n",
    "            df['NZ Bid Price adj'] = df['Bid Price adj']\n",
    "            df['NZ Ask Price adj'] = df['Ask Price adj']\n",
    "            df['NZ MidQuote adj'] = df['MidQuote adj']\n",
    "            # #adjust currency\n",
    "#             daily_fx = pd.read_csv('C:/Users/anche/NZ/trth data/3 month/daily fx 3 month.csv')\n",
    "#             daily_fx['date'] = pd.to_datetime(daily_fx['date']).dt.date\n",
    "#             daily_fx['midquote'] = pd.to_numeric(daily_fx['midquote'], errors = 'coerce')\n",
    "#             df = df.merge(daily_fx, on = ['date'], suffixes = ['','_fx'], how = 'left')\n",
    "#             df['Price'] = df['Price']*df['midquote']\n",
    "#             df['Bid Price'] = df['Bid Price']*df['midquote']\n",
    "#             df['Ask Price'] = df['Ask Price']*df['midquote']\n",
    "#             df['MidQuote'] = df['MidQuote']*df['midquote']\n",
    "\n",
    "#             df['Bid Price adj'] = df['Bid Price adj']*df['midquote']\n",
    "#             df['Ask Price adj'] = df['Ask Price adj']*df['midquote']\n",
    "#             df['MidQuote adj'] = df['MidQuote adj']*df['midquote']\n",
    "\n",
    "            #continue other metric\n",
    "            df['value'] = df['Price']*df['Volume']\n",
    "\n",
    "            df['old fee'] = df['value'].apply(lambda x: min(1+0.00002*x, 75)) \n",
    "            df['relative old fee'] = (df['old fee']/df['value'])*10000\n",
    "            df['new fee'] = df['value'].apply(lambda x: min(0.000045*x, 75))\n",
    "            df['relative new fee'] = (df['new fee']/df['value'])*10000\n",
    "            relative_old_fee = df.groupby(['date','stock'])['relative old fee'].mean().reset_index()\n",
    "            relative_new_fee = df.groupby(['date','stock'])['relative new fee'].mean().reset_index()\n",
    "\n",
    "            total_old_fee = df.groupby(['date','stock'])['old fee'].sum().reset_index()\n",
    "            total_new_fee = df.groupby(['date','stock'])['new fee'].sum().reset_index()\n",
    "\n",
    "            df['fee diff'] = df['new fee'] - df['old fee']\n",
    "            df['relative fee diff'] = df['fee diff']/df['value']\n",
    "            df['fee change'] = df['fee diff']/((df['new fee'] + df['old fee'])/2)\n",
    "            #per stock per day fee difference\n",
    "            fee_diff = df.groupby(['date','stock'])['fee diff'].sum().reset_index()\n",
    "            per_stock_fee_diff = fee_diff.groupby(['stock'])['fee diff'].mean().reset_index()\n",
    "\n",
    "            relative_fee_diff = df.groupby(['date','stock'])['relative fee diff'].mean().reset_index()\n",
    "\n",
    "            fee_change = df.groupby(['date','stock'])['fee change'].mean().reset_index()\n",
    "            per_stock_fee_change = fee_change.groupby(['stock'])['fee change'].mean().reset_index()\n",
    "\n",
    "            df['fee increase'] = np.where(df['new fee']>df['old fee'],1,0)\n",
    "            df['fee decrease'] = np.where(df['new fee']<df['old fee'],1,0)\n",
    "            df['fee unchanged'] = np.where(df['new fee']==df['old fee'],1,0)\n",
    "\n",
    "            df['trades'] = np.where(df['Price'].notnull(),1,0)\n",
    "            fee_increase = (df.groupby(['date','stock'])['fee increase'].sum()/df.groupby(['date','stock'])['trades'].sum()).reset_index()\n",
    "            fee_increase = fee_increase.rename(columns = {0:'perc_fee_increase'})\n",
    "            per_stock_fee_increase= fee_increase.groupby(['stock'])['perc_fee_increase'].mean().reset_index()\n",
    "\n",
    "            fee_merged = relative_old_fee.merge(relative_new_fee, on = ['date','stock'],how = 'outer')\n",
    "            fee_merged = fee_merged.merge(fee_diff, on = ['date','stock'],how = 'outer')\n",
    "            fee_merged = fee_merged.merge(relative_fee_diff, on = ['date','stock'],how = 'outer')\n",
    "            fee_merged = fee_merged.merge(fee_change, on = ['date','stock'],how = 'outer')\n",
    "            fee_merged = fee_merged.merge(fee_increase, on = ['date','stock'],how = 'outer')\n",
    "            fee_merged = fee_merged.merge(total_old_fee, on = ['date','stock'],how = 'outer')\n",
    "            fee_merged = fee_merged.merge(total_new_fee, on = ['date','stock'],how = 'outer')\n",
    "\n",
    "            df_fee = df[['stock','date','adj mtime','Qualifiers','value','Price','Volume','old fee','relative old fee','new fee','relative new fee','fee diff','relative fee diff','fee change']]\n",
    "\n",
    "            df_trades = df[df['Price'].notnull()]\n",
    "            #df.to_csv('C:/Users/anche/NZ/trth data/tester_out/'+'3_'+file_name)\n",
    "            #df = df[~df['Qualifiers'].isin(['LAM[GV4_TEXT]','LA[GV4_TEXT]','LTM[GV4_TEXT]','PF[GV4_TEXT]','PTM[GV4_TEXT]','SPM[GV4_TEXT]','SP[GV4_TEXT]','OL[GV4_TEXT]','OLM[GV4_TEXT]'])]\n",
    "            df['trad_direction'] = df['trad_direction'].astype(str)\n",
    "            df['Price'] = df['Price'].astype(float)\n",
    "            df['Bid Price'] = df['Bid Price'].astype(float)\n",
    "            df['Ask Price'] = df['Ask Price'].astype(float)\n",
    "            df['Volume'] = pd.to_numeric(df['Volume'], errors = 'coerce')\n",
    "            df['Bid Size abs'] = pd.to_numeric(df['Bid Size abs'],errors = 'coerce')\n",
    "            df['Ask Size abs'] = pd.to_numeric(df['Ask Size abs'],errors = 'coerce')\n",
    "            \n",
    "            \n",
    "            \n",
    "            df['issue'] = np.where(((df['trad_direction'] == 'S') & (df['Price'] < df['Bid Price'])) | (\n",
    "                    (df['trad_direction'] == 'B') & (df['Price'] > df['Ask Price'])), 1, 0)\n",
    "\n",
    "            df['vol_issue'] = np.where(((df['trad_direction'] == 'S') & (df['Volume'] > df['Bid Size abs'])) | (\n",
    "                    (df['trad_direction'] == 'B') & (df['Volume'] > df['Ask Size abs'])), 1, 0)\n",
    "\n",
    "            df['quote_alive'] = df.groupby(['stock','date','venue'])['adj mtime'].shift(-1) -  df['adj mtime']\n",
    "\n",
    "            df['Quoted Spread'] = np.where(\n",
    "                (df['Ask Price adj'] != 0) & (df['Bid Price adj'] != 0) & (df['Ask Price adj'] > df['Bid Price adj']),\n",
    "                df['Ask Price adj'] - df['Bid Price adj'], np.nan)\n",
    "            df['Quoted Spread bps'] = np.where(\n",
    "                    (df['Ask Price adj'] != 0) & (df['Bid Price adj'] != 0) & (df['Ask Price adj'] > df['Bid Price adj']),\n",
    "                    (df['Ask Price adj'] - df['Bid Price adj'])/(df['MidQuote adj']), np.nan)\n",
    "            df['Quoted Spread_TW'] = df['Quoted Spread'] * df['quote_alive']\n",
    "            df['Quoted Spread bps_TW'] = df['Quoted Spread bps'] * df['quote_alive']\n",
    "            \n",
    "            df['Depth'] = df['Bid Size abs'] + df['Ask Size abs']\n",
    "            df['Depth_TW'] = df['Depth'] * df['quote_alive']\n",
    "            \n",
    "            df['Depth_dollar'] = df['Bid Size abs']*df['Bid Price'] + df['Ask Size abs']*df['Ask Price']\n",
    "            df['Depth_dollar_TW'] = df['Depth_dollar'] * df['quote_alive']\n",
    "            \n",
    "\n",
    "            df[f'at tick'] = np.where(\n",
    "                        ((df['Quoted Spread'] < 0.01) & (df['MidQuote'] > 0.2)) | (\n",
    "                            (df['Quoted Spread'] < 0.001) & (df['MidQuote'] < 0.2)), 1, 0)\n",
    "            df[f'at tick time'] = df['at tick'] * df['quote_alive']\n",
    "            b_sel = df.trad_direction == 'B'\n",
    "            df.loc[b_sel, f'Effective Spread'] = 2 * (df.loc[b_sel, f'Price'] -df.loc[b_sel, 'MidQuote adj'])\n",
    "            s_sel = df.trad_direction == 'S'\n",
    "            df.loc[s_sel, f'Effective Spread'] = 2 * (df.loc[s_sel, 'MidQuote adj'] -df.loc[s_sel, f'Price'])\n",
    "            df['pos effective dummy'] = np.where(df['Effective Spread']>0,1,0)\n",
    "            df[f'Effective Spread_VW'] = df[f'Effective Spread'] * df[f'value']*df['pos effective dummy']\n",
    "            df.loc[b_sel, f'Effective Spread bps'] = 2 * (df.loc[b_sel, f'Price'] -df.loc[b_sel, 'MidQuote adj'])/df.loc[b_sel, 'MidQuote adj']\n",
    "            df.loc[s_sel, f'Effective Spread bps'] = 2 * (df.loc[s_sel, 'MidQuote adj'] -df.loc[s_sel, f'Price'])/df.loc[s_sel, 'MidQuote adj']\n",
    "\n",
    "            df[f'Effective Spread bps_VW'] = df[f'Effective Spread bps'] * df[f'value']*df['pos effective dummy']\n",
    "            df['value_weight'] = df[f'value']*df['pos effective dummy']\n",
    "            \n",
    "            df = df[(df['adj mtime'] > o_time) & (df['adj mtime'] < c_time)]\n",
    "\n",
    "            trade_value = df.groupby(['date','stock'])['value'].sum().reset_index()\n",
    "            trade_value = trade_value.rename(columns = {'value':'daily trade value'})\n",
    "\n",
    "            trade_size = df.groupby(['date','stock'])['value'].mean().reset_index()\n",
    "            trade_size = trade_size.rename(columns = {'value':'trade size'})\n",
    "\n",
    "            Quoted_spread_TW = (df.groupby(['stock', 'date'])['Quoted Spread_TW'].sum() / \\\n",
    "                                        df[df['Quoted Spread_TW'].notnull()].groupby(['stock', 'date'])['quote_alive'].sum()).reset_index()\n",
    "            Quoted_spread_TW = Quoted_spread_TW.rename(columns = {0:'quoted spread'})\n",
    "            \n",
    "            Depth_TW = (df.groupby(['stock', 'date'])['Depth_TW'].sum() / \\\n",
    "                                        df[df['Depth_TW'].notnull()].groupby(['stock', 'date'])['quote_alive'].sum()).reset_index()\n",
    "            Depth_TW = Depth_TW.rename(columns = {0:'Depth'})\n",
    "            \n",
    "            Depth_dollar_TW = (df.groupby(['stock', 'date'])['Depth_dollar_TW'].sum() / \\\n",
    "                                        df[df['Depth_TW'].notnull()].groupby(['stock', 'date'])['quote_alive'].sum()).reset_index()\n",
    "            Depth_dollar_TW = Depth_dollar_TW.rename(columns = {0:'Depth_dollar'})\n",
    "#             print(df.groupby(['stock', 'date'])['Quoted Spread'].sum())\n",
    "#             print(Quoted_spread_TW)\n",
    "\n",
    "            df['MidQuote_TW'] = df['MidQuote adj'] * df['quote_alive']\n",
    "\n",
    "            midpoint_TW = (df.groupby(['stock', 'date'])['MidQuote_TW'].sum() / \\\n",
    "                                            df[df['MidQuote_TW'].notnull()].groupby(['stock', 'date'])['quote_alive'].sum()).reset_index()\n",
    "            midpoint_TW = midpoint_TW.rename(columns = {0:'midpoint'})\n",
    "\n",
    "\n",
    "            Quoted_spread_bps_TW = (df.groupby(['stock', 'date'])['Quoted Spread bps_TW'].sum() / \\\n",
    "                                        df[df['Quoted Spread_TW'].notnull()].groupby(['stock', 'date'])['quote_alive'].sum()).reset_index()\n",
    "            Quoted_spread_bps_TW = Quoted_spread_bps_TW.rename(columns = {0:'quoted spread bps'})\n",
    "\n",
    "\n",
    "            min_tick_TW = (df.groupby(['stock', 'date'])['at tick time'].sum() / \\\n",
    "                                  df.groupby(['stock', 'date'])[\n",
    "                                      'quote_alive'].sum()).reset_index()\n",
    "            min_tick_TW = min_tick_TW.rename(columns = {0:'tick time'})\n",
    "\n",
    "            Value_weighted_Effective_Spread = (df.groupby(['stock', 'date'])['Effective Spread_VW'].sum() / \\\n",
    "                                        df[df['Effective Spread_VW'].notnull()].groupby(['stock', 'date'])['value_weight'].sum()).reset_index()\n",
    "\n",
    "            Value_weighted_Effective_Spread = Value_weighted_Effective_Spread.rename(columns = {0:'value weighted effective spread'})\n",
    "#             print(Value_weighted_Effective_Spread)\n",
    "            Value_weighted_Effective_Spread_bps = ((df.groupby(['stock', 'date'])['Effective Spread bps_VW'].sum() / \\\n",
    "                                        df[df['Effective Spread bps_VW'].notnull()].groupby(['stock', 'date'])['value_weight'].sum())*10000).reset_index()\n",
    "            Value_weighted_Effective_Spread_bps = Value_weighted_Effective_Spread_bps.rename(columns = {0:'value weighted effective spread bps'})\n",
    "\n",
    "            df = df.sort_values(['adj mtime','mtime_1s','mtime_30s','mtime_1m','mtime_5m'],ascending = True)\n",
    "\n",
    "            df_realized = pd.merge_asof(df,df[['stock','date','adj mtime','MidQuote adj']],left_on=['mtime_1s'], right_on=['adj mtime'],\n",
    "                                                 by=['stock','date'], suffixes=('', '_1s_matched'),\n",
    "                                                 allow_exact_matches=True)\n",
    "            df_realized = pd.merge_asof(df_realized,df[['stock','date','adj mtime','MidQuote adj']],left_on=['mtime_30s'], right_on=['adj mtime'],\n",
    "                                                 by=['stock','date'], suffixes=('', '_30s_matched'),\n",
    "                                                 allow_exact_matches=True)\n",
    "            df_realized = pd.merge_asof(df_realized,df[['stock','date','adj mtime','MidQuote adj']],left_on=['mtime_1m'], right_on=['adj mtime'],\n",
    "                                                 by=['stock','date'], suffixes=('', '_1m_matched'),\n",
    "                                                 allow_exact_matches=True)\n",
    "            df_realized = pd.merge_asof(df_realized,df[['stock','date','adj mtime','MidQuote adj']],left_on=['mtime_5m'], right_on=['adj mtime'],\n",
    "                                                 by=['stock','date'], suffixes=('', '_5m_matched'),\n",
    "                                                 allow_exact_matches=True)\n",
    "            #1s\n",
    "            b_sel = df_realized.trad_direction == 'B'\n",
    "            df_realized.loc[b_sel, f'Realized Spread 1s'] = 2 * (df_realized.loc[b_sel, f'Price'] -df_realized.loc[b_sel, 'MidQuote adj_1s_matched'])\n",
    "            s_sel = df_realized.trad_direction == 'S'\n",
    "            df_realized.loc[s_sel, f'Realized Spread 1s'] = 2 * (df_realized.loc[s_sel, 'MidQuote adj_1s_matched'] -df_realized.loc[s_sel, f'Price'])\n",
    "\n",
    "            df_realized[f'Realized Spread 1s_VW'] = df_realized[f'Realized Spread 1s'] * df_realized[f'value']*df_realized['pos effective dummy']\n",
    "            df_realized.loc[b_sel, f'Realized Spread 1s bps'] = 2 * (df_realized.loc[b_sel, f'Price'] -df_realized.loc[b_sel, 'MidQuote adj_1s_matched'])/df_realized.loc[b_sel, 'MidQuote adj_1s_matched']\n",
    "            df_realized.loc[s_sel, f'Realized Spread 1s bps'] = 2 * (df_realized.loc[s_sel, 'MidQuote adj_1s_matched'] -df_realized.loc[s_sel, f'Price'])/df_realized.loc[s_sel, 'MidQuote adj_1s_matched']\n",
    "\n",
    "            df_realized[f'Realized Spread 1s bps_VW'] = df_realized[f'Realized Spread 1s bps'] * df_realized[f'value']*df_realized['pos effective dummy']\n",
    "#             df_spreads = df_realized[df_realized['Price'].notnull()][['stock','date','adj mtime','Qualifiers','value','NZ Price','NZ MidQuote adj','Price','Volume','direction','Bid Price adj','Ask Price adj','NZ Bid Price adj','NZ Ask Price adj','Effective Spread','Realized Spread','Effective Spread bps','Realized Spread bps','MidQuote adj','MidQuote adj_1m_matched','Quoted Spread','Quoted Spread bps']]\n",
    "           \n",
    "            Value_weighted_Realized_Spread_1s = (df_realized.groupby(['stock', 'date'])['Realized Spread 1s_VW'].sum() / \\\n",
    "                                        df_realized[df_realized['Realized Spread 1s_VW'].notnull()].groupby(['stock', 'date'])['value_weight'].sum()).reset_index()\n",
    "\n",
    "            Value_weighted_Realized_Spread_1s = Value_weighted_Realized_Spread_1s.rename(columns = {0:'value weighted realized spread 1s'})\n",
    "\n",
    "            Value_weighted_Realized_Spread_1s_bps = ((df_realized.groupby(['stock', 'date'])['Realized Spread 1s bps_VW'].sum() / \\\n",
    "                                        df_realized[df_realized['Realized Spread 1s bps_VW'].notnull()].groupby(['stock', 'date'])['value_weight'].sum())*10000).reset_index()\n",
    "            Value_weighted_Realized_Spread_1s_bps = Value_weighted_Realized_Spread_1s_bps.rename(columns = {0:'value weighted realized spread 1s bps'})\n",
    "\n",
    "            #30s\n",
    "            \n",
    "            df_realized.loc[b_sel, f'Realized Spread 30s'] = 2 * (df_realized.loc[b_sel, f'Price'] -df_realized.loc[b_sel, 'MidQuote adj_30s_matched'])\n",
    "            \n",
    "            df_realized.loc[s_sel, f'Realized Spread 30s'] = 2 * (df_realized.loc[s_sel, 'MidQuote adj_30s_matched'] -df_realized.loc[s_sel, f'Price'])\n",
    "\n",
    "            df_realized[f'Realized Spread 30s_VW'] = df_realized[f'Realized Spread 30s'] * df_realized[f'value']*df_realized['pos effective dummy']\n",
    "            df_realized.loc[b_sel, f'Realized Spread 30s bps'] = 2 * (df_realized.loc[b_sel, f'Price'] -df_realized.loc[b_sel, 'MidQuote adj_30s_matched'])/df_realized.loc[b_sel, 'MidQuote adj_1s_matched']\n",
    "            df_realized.loc[s_sel, f'Realized Spread 30s bps'] = 2 * (df_realized.loc[s_sel, 'MidQuote adj_30s_matched'] -df_realized.loc[s_sel, f'Price'])/df_realized.loc[s_sel, 'MidQuote adj_1s_matched']\n",
    "\n",
    "            df_realized[f'Realized Spread 30s bps_VW'] = df_realized[f'Realized Spread 30s bps'] * df_realized[f'value']*df_realized['pos effective dummy']\n",
    "           \n",
    "            Value_weighted_Realized_Spread_30s = (df_realized.groupby(['stock', 'date'])['Realized Spread 30s_VW'].sum() / \\\n",
    "                                        df_realized[df_realized['Realized Spread 30s_VW'].notnull()].groupby(['stock', 'date'])['value_weight'].sum()).reset_index()\n",
    "\n",
    "            Value_weighted_Realized_Spread_30s = Value_weighted_Realized_Spread_30s.rename(columns = {0:'value weighted realized spread 30s'})\n",
    "\n",
    "            Value_weighted_Realized_Spread_30s_bps = ((df_realized.groupby(['stock', 'date'])['Realized Spread 30s bps_VW'].sum() / \\\n",
    "                                        df_realized[df_realized['Realized Spread 30s bps_VW'].notnull()].groupby(['stock', 'date'])['value_weight'].sum())*10000).reset_index()\n",
    "            Value_weighted_Realized_Spread_30s_bps = Value_weighted_Realized_Spread_30s_bps.rename(columns = {0:'value weighted realized spread 30s bps'})\n",
    "\n",
    "            #1m\n",
    "            \n",
    "            df_realized.loc[b_sel, f'Realized Spread 1m'] = 2 * (df_realized.loc[b_sel, f'Price'] -df_realized.loc[b_sel, 'MidQuote adj_1m_matched'])\n",
    "            \n",
    "            df_realized.loc[s_sel, f'Realized Spread 1m'] = 2 * (df_realized.loc[s_sel, 'MidQuote adj_1m_matched'] -df_realized.loc[s_sel, f'Price'])\n",
    "\n",
    "            df_realized[f'Realized Spread 1m_VW'] = df_realized[f'Realized Spread 1m'] * df_realized[f'value']*df_realized['pos effective dummy']\n",
    "            df_realized.loc[b_sel, f'Realized Spread 1m bps'] = 2 * (df_realized.loc[b_sel, f'Price'] -df_realized.loc[b_sel, 'MidQuote adj_1m_matched'])/df_realized.loc[b_sel, 'MidQuote adj_1m_matched']\n",
    "            df_realized.loc[s_sel, f'Realized Spread 1m bps'] = 2 * (df_realized.loc[s_sel, 'MidQuote adj_1m_matched'] -df_realized.loc[s_sel, f'Price'])/df_realized.loc[s_sel, 'MidQuote adj_1m_matched']\n",
    "\n",
    "            df_realized[f'Realized Spread 1m bps_VW'] = df_realized[f'Realized Spread 1m bps'] * df_realized[f'value']*df_realized['pos effective dummy']\n",
    "           \n",
    "            Value_weighted_Realized_Spread_1m = (df_realized.groupby(['stock', 'date'])['Realized Spread 1m_VW'].sum() / \\\n",
    "                                        df_realized[df_realized['Realized Spread 1m_VW'].notnull()].groupby(['stock', 'date'])['value_weight'].sum()).reset_index()\n",
    "\n",
    "            Value_weighted_Realized_Spread_1m = Value_weighted_Realized_Spread_1m.rename(columns = {0:'value weighted realized spread 1m'})\n",
    "\n",
    "            Value_weighted_Realized_Spread_1m_bps = ((df_realized.groupby(['stock', 'date'])['Realized Spread 1m bps_VW'].sum() / \\\n",
    "                                        df_realized[df_realized['Realized Spread 1m bps_VW'].notnull()].groupby(['stock', 'date'])['value_weight'].sum())*10000).reset_index()\n",
    "            Value_weighted_Realized_Spread_1m_bps = Value_weighted_Realized_Spread_1m_bps.rename(columns = {0:'value weighted realized spread 1m bps'})\n",
    "\n",
    "            #5m\n",
    "        \n",
    "            df_realized.loc[b_sel, f'Realized Spread 5m'] = 2 * (df_realized.loc[b_sel, f'Price'] -df_realized.loc[b_sel, 'MidQuote adj_5m_matched'])\n",
    "            \n",
    "            df_realized.loc[s_sel, f'Realized Spread 5m'] = 2 * (df_realized.loc[s_sel, 'MidQuote adj_5m_matched'] -df_realized.loc[s_sel, f'Price'])\n",
    "\n",
    "            df_realized[f'Realized Spread 5m_VW'] = df_realized[f'Realized Spread 5m'] * df_realized[f'value']*df_realized['pos effective dummy']\n",
    "            df_realized.loc[b_sel, f'Realized Spread 5m bps'] = 2 * (df_realized.loc[b_sel, f'Price'] -df_realized.loc[b_sel, 'MidQuote adj_5m_matched'])/df_realized.loc[b_sel, 'MidQuote adj_5m_matched']\n",
    "            df_realized.loc[s_sel, f'Realized Spread 5m bps'] = 2 * (df_realized.loc[s_sel, 'MidQuote adj_5m_matched'] -df_realized.loc[s_sel, f'Price'])/df_realized.loc[s_sel, 'MidQuote adj_5m_matched']\n",
    "\n",
    "            df_realized[f'Realized Spread 5m bps_VW'] = df_realized[f'Realized Spread 5m bps'] * df_realized[f'value']*df_realized['pos effective dummy']\n",
    "           \n",
    "            Value_weighted_Realized_Spread_5m = (df_realized.groupby(['stock', 'date'])['Realized Spread 5m_VW'].sum() / \\\n",
    "                                        df_realized[df_realized['Realized Spread 5m_VW'].notnull()].groupby(['stock', 'date'])['value_weight'].sum()).reset_index()\n",
    "\n",
    "            Value_weighted_Realized_Spread_5m = Value_weighted_Realized_Spread_5m.rename(columns = {0:'value weighted realized spread 5m'})\n",
    "\n",
    "            Value_weighted_Realized_Spread_5m_bps = ((df_realized.groupby(['stock', 'date'])['Realized Spread 5m bps_VW'].sum() / \\\n",
    "                                        df_realized[df_realized['Realized Spread 5m bps_VW'].notnull()].groupby(['stock', 'date'])['value_weight'].sum())*10000).reset_index()\n",
    "            Value_weighted_Realized_Spread_5m_bps = Value_weighted_Realized_Spread_5m_bps.rename(columns = {0:'value weighted realized spread 5m bps'})\n",
    "            #df_realized.to_csv('C://Users//anche//NZ//tables update//check//'+df['date'].astype(str).iloc[0]+df['stock'].iloc[0]+'.csv')\n",
    "\n",
    "            #compute market order \n",
    "            #market_order = df.groupby(['stock','date','adj mtime'])['value'].sum().reset_index()\n",
    "\n",
    "            #daily_market_order = market_order.groupby(['stock','date'])['value'].mean().reset_index()\n",
    "            #daily_market_order = daily_market_order.rename(columns = {'value':'market order value'})\n",
    "            \n",
    "            ##########################for buyer initiated##############################\n",
    "\n",
    "\n",
    "            df_trades_buy = df.loc[\n",
    "                (df['direction'] == 'B')]  \n",
    "            if len(df_trades_buy)>1:\n",
    "                df_trades_buy = df_trades_buy.reset_index()\n",
    "                #if the difference in time between each two trades is more than 200, then start a new trade string \n",
    "                df_trades_buy['trade_dif'] = df_trades_buy['adj mtime'] - df_trades_buy.groupby(['date','stock'])['adj mtime'].shift()\n",
    "                \n",
    "                df_trades_buy['trade_string_index'] = int()\n",
    "\n",
    "                df_trades_buy['trade_string_index'] = (df_trades_buy['trade_dif'] > 200000).cumsum()\n",
    "                \n",
    "                buy_string_market_order = df_trades_buy.groupby(['date','stock','trade_string_index'])['value'].sum().rename('market_order').reset_index()\n",
    "                buy_string_limit_order = df_trades_buy.groupby(['date','stock','trade_string_index'])['value'].apply(lambda x: x.iloc[-1:].mean()).rename('limit_order').reset_index()\n",
    "\n",
    "                buy_market_order = buy_string_market_order.groupby(['date','stock'])['market_order'].mean().rename('buy_market_order').reset_index()\n",
    "                buy_limit_order = buy_string_limit_order.groupby(['date','stock'])['limit_order'].mean().rename('buy_limit_order').reset_index()\n",
    "                \n",
    "                #print(buy_limit_order)\n",
    "            \n",
    "            df_trades_sell = df.loc[\n",
    "                (df['direction'] == 'S')]  \n",
    "            if len(df_trades_sell)>1:\n",
    "                df_trades_sell = df_trades_sell.reset_index()\n",
    "                df_trades_sell['trade_dif'] = df_trades_sell['adj mtime'] - df_trades_sell.groupby(['date','stock'])['adj mtime'].shift()\n",
    "                \n",
    "                df_trades_sell['trade_string_index'] = int()\n",
    "\n",
    "                df_trades_sell['trade_string_index'] = (df_trades_sell['trade_dif'] > 200000).cumsum()\n",
    "                sell_string_market_order = df_trades_sell.groupby(['date','stock','trade_string_index'])['value'].sum().rename('market_order').reset_index()\n",
    "                sell_string_limit_order = df_trades_sell.groupby(['date','stock','trade_string_index'])['value'].apply(lambda x: x.iloc[-1:].mean()).rename('limit_order').reset_index()\n",
    "                \n",
    "                sell_market_order = sell_string_market_order.groupby(['date','stock'])['market_order'].mean().rename('sell_market_order').reset_index()\n",
    "                sell_limit_order = sell_string_limit_order.groupby(['date','stock'])['limit_order'].mean().rename('sell_limit_order').reset_index()\n",
    "                #print(sell_limit_order)\n",
    "            #all_type_orders = buy_market_order.merge(buy_limit_order, on = ['date','stock']).merge(sell_market_order, on = ['date','stock']).merge(sell_limit_order, on = ['date','stock'])\n",
    "            \n",
    "            '''\n",
    "            #compute limit order\n",
    "\n",
    "            df['bid diff'] = df.groupby(['stock','venue','date'])['Bid Price'].diff() \n",
    "            df['bid order'] = np.where(df['bid diff']==0,df.groupby(['stock','venue','date'])['Bid Size abs'].diff(),np.nan )\n",
    "            df['bid order'] = np.where(df['bid diff']>0,df['Bid Size abs'],df['bid order'])\n",
    "\n",
    "            df['bid order'] = np.where(df['bid order']>0,df['bid order'],np.nan)\n",
    "\n",
    "            df['ask diff'] = df.groupby(['stock','venue','date'])['Ask Price'].diff() \n",
    "            df['ask order'] = np.where(df['ask diff']==0,df.groupby(['stock','venue','date'])['Ask Size abs'].diff(),np.nan )\n",
    "            df['ask order'] = np.where(df['ask diff']<0,df['Ask Size abs'],df['ask order'])\n",
    "            df['ask order'] = np.where(df['ask order']>0,df['ask order'],np.nan)\n",
    "\n",
    "            daily_bid_order = df.groupby(['stock','date'])['bid order'].mean().reset_index()\n",
    "            daily_bid_order = daily_bid_order.rename(columns = {'bid order':'bid order value'})\n",
    "\n",
    "            daily_ask_order = df.groupby(['stock','date'])['ask order'].mean().reset_index()\n",
    "            daily_ask_order = daily_ask_order.rename(columns = {'ask order':'ask order value'})\n",
    "\n",
    "            daily_order = daily_bid_order.merge(daily_ask_order, on = ['stock','date'])\n",
    "\n",
    "            '''\n",
    "            num_quote_update = df.groupby(['stock','date'])['Bid Price'].count().reset_index()\n",
    "            num_quote_update = num_quote_update.rename(columns = {'Bid Price':'num_quote_update'})\n",
    "\n",
    "            num_trades = df.groupby(['stock','date'])['Price'].count().reset_index()\n",
    "            num_trades = num_trades.rename(columns = {'Price':'num_trades'})\n",
    "\n",
    "            fee_diff['date'] = pd.to_datetime(fee_diff['date'])\n",
    "            fee_change['date'] = pd.to_datetime(fee_change['date'])\n",
    "            fee_increase['date'] = pd.to_datetime(fee_increase['date'])\n",
    "            # daily_value['date'] = pd.to_datetime(daily_value['date'])\n",
    "            trade_value['date'] = pd.to_datetime(trade_value['date'])\n",
    "            Quoted_spread_TW['date'] = pd.to_datetime(Quoted_spread_TW['date'])\n",
    "            Depth_TW['date'] = pd.to_datetime(Depth_TW['date'])\n",
    "            Depth_dollar_TW['date'] = pd.to_datetime(Depth_dollar_TW['date'])\n",
    "            min_tick_TW['date'] = pd.to_datetime(min_tick_TW['date'])\n",
    "            Value_weighted_Effective_Spread['date'] = pd.to_datetime(Value_weighted_Effective_Spread['date'])\n",
    "            Value_weighted_Effective_Spread_bps['date'] = pd.to_datetime(Value_weighted_Effective_Spread_bps['date'])\n",
    "            Value_weighted_Realized_Spread_1s['date'] = pd.to_datetime(Value_weighted_Realized_Spread_1s['date'])\n",
    "            Value_weighted_Realized_Spread_1s_bps['date'] = pd.to_datetime(Value_weighted_Realized_Spread_1s_bps['date'])\n",
    "            \n",
    "            Value_weighted_Realized_Spread_30s['date'] = pd.to_datetime(Value_weighted_Realized_Spread_30s['date'])\n",
    "            Value_weighted_Realized_Spread_30s_bps['date'] = pd.to_datetime(Value_weighted_Realized_Spread_30s_bps['date'])\n",
    "            Value_weighted_Realized_Spread_1m['date'] = pd.to_datetime(Value_weighted_Realized_Spread_1m['date'])\n",
    "            Value_weighted_Realized_Spread_1m_bps['date'] = pd.to_datetime(Value_weighted_Realized_Spread_1m_bps['date'])\n",
    "            Value_weighted_Realized_Spread_5m['date'] = pd.to_datetime(Value_weighted_Realized_Spread_5m['date'])\n",
    "            Value_weighted_Realized_Spread_5m_bps['date'] = pd.to_datetime(Value_weighted_Realized_Spread_5m_bps['date'])\n",
    "\n",
    "            \n",
    "            \n",
    "            #             daily_market_order['date'] = pd.to_datetime(daily_market_order['date'])\n",
    "#             daily_order['date'] = pd.to_datetime(daily_order['date'])\n",
    "            num_quote_update['date'] = pd.to_datetime(num_quote_update['date'])\n",
    "            num_trades['date'] = pd.to_datetime(num_trades['date'])\n",
    "            midpoint_TW['date'] = pd.to_datetime(midpoint_TW['date'])\n",
    "            \n",
    "            trade_size['date'] = pd.to_datetime(trade_size['date'])\n",
    "            try:\n",
    "                buy_market_order['date'] = pd.to_datetime(buy_market_order['date'])\n",
    "                buy_limit_order['date'] = pd.to_datetime(buy_limit_order['date'])\n",
    "            except:\n",
    "                print(filename)\n",
    "            try:    \n",
    "                sell_market_order['date'] = pd.to_datetime(sell_market_order['date'])\n",
    "                sell_limit_order['date'] = pd.to_datetime(sell_limit_order['date'])\n",
    "\n",
    "            except:\n",
    "                print(filename)\n",
    "            all_metric = fee_diff.merge(fee_change, on = ['stock','date'], how = 'outer').merge(fee_increase, on = ['stock','date'], how = 'outer')\n",
    "            all_metric = all_metric.merge(trade_value, on = ['stock','date'], how = 'outer')\n",
    "            all_metric = all_metric.merge(Quoted_spread_TW,on = ['stock','date'], how = 'outer')\n",
    "            all_metric = all_metric.merge(Depth_TW,on = ['stock','date'], how = 'outer')\n",
    "            all_metric = all_metric.merge(Depth_dollar_TW,on = ['stock','date'], how = 'outer')\n",
    "            all_metric = all_metric.merge(min_tick_TW,on = ['stock','date'], how = 'outer')\n",
    "            all_metric = all_metric.merge(Value_weighted_Effective_Spread,on = ['stock','date'], how = 'outer')\n",
    "            all_metric = all_metric.merge(Value_weighted_Effective_Spread_bps,on = ['stock','date'], how = 'outer')\n",
    "            all_metric = all_metric.merge(Value_weighted_Realized_Spread_1s,on = ['stock','date'], how = 'outer')\n",
    "            all_metric = all_metric.merge(Value_weighted_Realized_Spread_1s_bps,on = ['stock','date'], how = 'outer')\n",
    "            all_metric = all_metric.merge(Value_weighted_Realized_Spread_30s,on = ['stock','date'], how = 'outer')\n",
    "            all_metric = all_metric.merge(Value_weighted_Realized_Spread_30s_bps,on = ['stock','date'], how = 'outer')\n",
    "            all_metric = all_metric.merge(Value_weighted_Realized_Spread_1m,on = ['stock','date'], how = 'outer')\n",
    "            all_metric = all_metric.merge(Value_weighted_Realized_Spread_1m_bps,on = ['stock','date'], how = 'outer')\n",
    "            all_metric = all_metric.merge(Value_weighted_Realized_Spread_5m,on = ['stock','date'], how = 'outer')\n",
    "            all_metric = all_metric.merge(Value_weighted_Realized_Spread_5m_bps,on = ['stock','date'], how = 'outer')\n",
    "#             all_metric = all_metric.merge(daily_market_order,on = ['stock','date'], how = 'outer')\n",
    "#             all_metric = all_metric.merge(daily_order,on = ['stock','date'], how = 'outer')\n",
    "            all_metric = all_metric.merge(num_quote_update,on = ['stock','date'], how = 'outer')\n",
    "            all_metric = all_metric.merge(num_trades,on = ['stock','date'], how = 'outer')\n",
    "            all_metric = all_metric.merge(midpoint_TW,on = ['stock','date'], how = 'outer')\n",
    "            all_metric = all_metric.merge(trade_size,on = ['stock','date'], how = 'outer')\n",
    "            try:\n",
    "                all_metric = all_metric.merge(buy_market_order,on = ['stock','date'], how = 'outer')\n",
    "                all_metric = all_metric.merge(buy_limit_order,on = ['stock','date'], how = 'outer')\n",
    "            except:\n",
    "                print(filename)\n",
    "            try:\n",
    "                all_metric = all_metric.merge(sell_market_order,on = ['stock','date'], how = 'outer')\n",
    "                all_metric = all_metric.merge(sell_limit_order,on = ['stock','date'], how = 'outer')\n",
    "            except:\n",
    "                print(filename)\n",
    "            \n",
    "            return (all_metric,df_trades,fee_merged,df_fee)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T05:58:23.250257Z",
     "start_time": "2019-10-21T02:59:33.389688Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('C:/Users/anche/NZ/trth data/NZALL TAQ')\n",
    "metric_list = []\n",
    "trades_list = []\n",
    "fee_merged_list = []\n",
    "fee_list = []\n",
    "spreads_list = []\n",
    "for file in os.listdir('C:/Users/anche/NZ/trth data/NZALL TAQ'):\n",
    "    try:\n",
    "#         if 'TWR.NZ' in file:\n",
    "        \n",
    "            metric_list.append(metric(file)[0])\n",
    "            trades_list.append(metric(file)[1])\n",
    "            #fee_merged_list.append(metric(file)[2])\n",
    "            #fee_list.append(metric(file)[3])\n",
    "            #spreads_list.append(metric(file)[4])\n",
    "            #metric(file)[4].to_csv('C:/Users/anche/NZ/tables v2/NZ new/stock days whole/'+file.split('/')[-1])\n",
    "    except:\n",
    "        print(file,'something')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T05:58:38.612210Z",
     "start_time": "2019-10-21T05:58:23.253250Z"
    }
   },
   "outputs": [],
   "source": [
    "all_metrics = pd.concat(metric_list)\n",
    "all_metrics.to_csv('C:/Users/anche/NZ/tables update/NZ metric allord v9.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T05:59:44.961924Z",
     "start_time": "2019-10-21T05:58:38.614166Z"
    }
   },
   "outputs": [],
   "source": [
    "all_trades = pd.concat(trades_list)\n",
    "all_trades.to_csv('C:/Users/anche/NZ/tables update/NZ trades allord v9.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T07:59:35.520814Z",
     "start_time": "2019-10-01T07:59:35.376202Z"
    }
   },
   "outputs": [],
   "source": [
    "all_metrics = pd.concat(metric_list)\n",
    "all_metrics.to_csv('C://Users//anche//NZ//tables update//check//TWR.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T00:54:26.866592Z",
     "start_time": "2019-09-30T00:54:26.835421Z"
    }
   },
   "outputs": [],
   "source": [
    "# all_trades = pd.concat(trades_list)\n",
    "# all_trades.to_csv('C://Users//anche//NZ//tables update//check//AIRNZ.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fee_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T05:10:04.757129Z",
     "start_time": "2019-10-01T05:10:04.578567Z"
    }
   },
   "outputs": [],
   "source": [
    "all_fee_merged = pd.concat(fee_merged_list)\n",
    "all_fee_merged.to_csv('C:/Users/anche/NZ/tables v2/NZ all_fee_merged allord v9.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T05:10:04.761300Z",
     "start_time": "2019-10-01T02:45:33.750Z"
    }
   },
   "outputs": [],
   "source": [
    "all_fee = pd.concat(fee_list)\n",
    "all_fee.to_csv('C:/Users/anche/NZ/tables v2/NZ all_fee allord v9.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T05:10:04.763296Z",
     "start_time": "2019-10-01T02:45:34.092Z"
    }
   },
   "outputs": [],
   "source": [
    "all_spreads = pd.concat(spreads_list)\n",
    "all_spreads.to_csv('C:/Users/anche/NZ/tables v2/NZ all_spreads allord v9.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
